<!DOCTYPE html>
<html class="no-js" lang="en">

<head>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-113408615-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-113408615-1');
    </script>

    <!--- basic page needs
    ================================================== -->
    <meta charset="utf-8">
    <title>Sahib Dhanjal | Roboticist</title>
    <meta name="author" content="Sahib Singh Dhanjal">
    <meta name="description" content=" Sahib Singh Dhanjal Portfolio website">
    <meta name="keywords" content="portfolio, star wars, star, wars, robot, robotics, roboticist, University, of, michigan, university of michigan, ann arbor, flint, dearborn, bits, pilani, birla institute of technology and science, birla, institute, technology, science, pilani, hyderabad, goa, personal, projects, robot Kinematic, kinematics, path planner, path, planning, turtlebot, masters, football, soccer, Programmer, coder, coding, programming, machine learning, deep learning, tensor flow, computer vision, C/C++, JavaScript, java, python,Formula, student, fsae, italy, robotx, maritime, autonmous, slam, localization, mapping, vehicle, dynamics, inspired, Karters, fs">

    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <link rel="stylesheet" href="css/base.css">
    <link rel="stylesheet" href="css/vendor.css">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/fonts.css">

    <!-- script
    ================================================== -->
    <script src="js/modernizr.js"></script>
    <script src="js/pace.min.js"></script>

    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="icon" href="images/favicon.ico" type="image/x-icon">


</head>

<body id="top">

    <!-- header
    ================================================== -->
    <header class="s-header">
        <div class="header-logo">
            <a class="site-logo" href="index.html">
                <h1 style="font-family: sans-serif; font-size: 3rem; color: white; font-family: domine-bold, sans-serif;">
                    Sahib Dhanjal
                </h1>
            </a>
        </div>
        <div class="nav-mobile">
            <a id="nav-toggle" href="#!"><span></span></a>
        </div>
        <nav class="header-nav">
            <ul class="header-nav__list">
                <li class="current"><a href="#home">Work</a></li>
                <li><a href="https://medium.com/@sahibdhanjal" target="_blank">Blog</a></li>
                <li><a href="https://docs.google.com/document/d/1t2QLEwItGmX8AOK7teRTdotwSPwrbQxdyiDk8b1ZrA4/" target="_blank">Resume</a></li>
            </ul>
        </nav>
    </header>


    <!-- home
    ================================================== -->
    <section id="home" class="s-home target-section" data-parallax="scroll" data-position-y=top>
        <div class="fancy-text" style="height: 30em; position: relative;">
            <svg class="fancy-text__main center">
                <symbol id="s-text">
                    <text text-anchor="middle" x="50%" y="80%">Hello World</text>
                </symbol>
                <g class = "g-ants">
                    <use xlink:href="#s-text" class="text-copy"></use>
                    <use xlink:href="#s-text" class="text-copy"></use>
                    <use xlink:href="#s-text" class="text-copy"></use>
                    <use xlink:href="#s-text" class="text-copy"></use>
                    <use xlink:href="#s-text" class="text-copy"></use>
                </g>
            </svg>
        </div>
    </section>
    <!-- end s-home -->

   <!-- projects
    ================================================== -->
    <section id='works' class="s-works">

        <div class="row masonry-wrap">
            <div class="masonry">


                <!-- NASA ASTRONET -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-nasa.jpg" class="thumb-link" title="NASA Astronet" data-size="2100x1400">
                                <img src="images/portfolio/nasa.jpg" srcset="images/portfolio/nasa.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">NASA Astronet</h3>
                            <p class="item-folio__cat">
                                A Human-Centric Network of Co-Robots
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <div class="item-folio__caption">
                            <p style="margin-bottom: 1rem">The <a href="https://www.nasa.gov/directorates/spacetech/strg/ecf2016/AstroNet.html">AstroNet</a> Simulator is developed as an extension to NASA's <a href="https://www.nasa.gov/astrobee">open-source simulator</a>. Coverage and navigation algorithms for each of the Astrobee Robots are developed in an immersive VR-based ISS environment. <a href="http://wiki.ros.org/kinetic">ROS Kinetic</a> is used for simulating the algorithms, and to interface with the quadcopters (representing astrobee robots in our environment). An immersive VR-based environment of the whole International Space Station, with the robots in it, has been implemented and can be visualized on the <a href="https://www.oculus.com/rift/#oui-csl-rift-games=robo-recall">Oculus Rift</a>.</p>
                            <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/NASA-Astrobee" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                            <a class="btn btn--strokeinv full-width" href="https://vimeo.com/282063033" target="_blank" style="width: 30%; margin-left: 0;">Demo</a>

                        </div>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->


                <!-- RobotX -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-wamv.jpg" class="thumb-link" title="RobotX WAM-V" data-size="2100x1400">
                                <img src="images/portfolio/wamv.jpg" srcset="images/portfolio/wamv.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">AUVSI RobotX</h3>
                            <p class="item-folio__cat">
                                Autonomous Surface Vessel Competition
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <div class="item-folio__caption">
                            <p style="margin-bottom: 1rem">AUVSI's <a href="http://robotx.org/">Robot-X</a> competition is an attempt at automating surface vessels to revolutionize the marine industry. The robot should be capable of performing several tasks such as SLAM, Trajectory Planning, Obstacle Avoidance, etc. My contributions to the project are in SLAM(Velodyne HDL32, Ladybug 3 and GPS/IMU module used as sensors), Trajectory Planning, 3D Object Detection, and Network and Communication Setup. The whole framework is being developed on ROS Kinetic.</p>
                            <a class="btn btn--strokeinv full-width" href="https://github.com/MichiganRobotX/" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                        </div>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->



                <!-- Path Planning | Exploration -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">


                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-turt.jpg" class="thumb-link" title="TurtleBot 2" data-size="2100x1400">
                                <img src="images/portfolio/turt.jpg" srcset="images/portfolio/turt.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Path Planning | Exploration</h3>
                            <p class="item-folio__cat">
                                Multi-Agent exploration in Turtlebots
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <div class="item-folio__caption">
                            <p style="margin-bottom: 1rem">This project involves comparative analysis of state-of-the-art path planning and multi-agent exploration algorithms via simulation and experimentation. Simmulations are performed on 50+ fabricated grid maps of size 50 x 50 on a python based simulator. To validate the results, experiments with <a href="https://www.turtlebot.com/turtlebot2/">Turtlebots</a> are also performed. Nodes for the studied path planning and exploration algorithms are written and 10 different laboratory environments are explored.</p>
                            <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/Path-Planning-Simulator" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                            <a class="btn btn--strokeinv full-width" href="projects/path planning simulator/index.html" target="_blank" style="width: 30%; margin-left: 0;">Demo</a>
                        </div>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->


                <!-- PoseNet++ -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-posenet.jpg" class="thumb-link" title="Cambridge Dataset" data-size="2100x1400">
                                <img src="images/portfolio/posenet.jpg" srcset="images/portfolio/posenet.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">PoseNet++</h3>
                            <p class="item-folio__cat">
                                Deep Learning in SLAM
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">An online-deep learning based-data labeling paradigm derived from structural motion is implemented. We directly label (6-DOF measurements) the input data (camera video feed) streamed from a mobile camera using this paradigm. This labeled data is then used to train <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf">PoseNet</a>, which acts as the sensor model for <a href="http://people.csail.mit.edu/kaess/isam/">Incremental Smoothing and Mapping (iSAM)</a>. GPS data from the used dataset's is used to build the action model. Georgia Tech's <a href="https://borg.cc.gatech.edu/">GTSAM</a> is then used for simulation. The algorithm is also implemented on a differential drive mobile robot.</p>
                            <a class="btn btn--strokeinv full-width" href="https://posenet-mobile-robot.github.io/" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Radio-Localization  -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-wifi.jpg" class="thumb-link" title="Kinematics Simulator" data-size="2100x1400">
                                <img src="images/portfolio/wifi.jpg" srcset="images/portfolio/wifi.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Visual-Radio-Inertial Localization</h3>
                            <p class="item-folio__cat">
                                an Indoor Positioning System based on WiFi
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">This project involved the development of a localization system for truly mobile devices, such as smartphones. The main aim of the project is to provide a means of localization in indoor/GPS-denied environments. A deep neural network capable of differentiating between LOS/NLOS measurements has been architected. Simulations in MATLAB and Python have been developed for the 2D and 3D case. Experiments with the <a href="https://fetchrobotics.com/robotics-platforms/fetch-mobile-manipulator/">Fetch</a> robot were performed with an RMSE of around 2m. The project was done under the guidance of <a href="https://www.maanighaffari.com/">Dr. Maani Ghaffari</a>.</p>

                            <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/DeepLocNet" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- FSAE -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-fs.jpg" class="thumb-link" title="Formula SAE" data-size="2100x1400">
                                <img src="images/portfolio/fs.jpg" srcset="images/portfolio/fs.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Formula SAE Italy</h3>
                            <p class="item-folio__cat">
                                Formula Prototype Competition
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">SAE holds it's annual international competiton at different locations to pit the best teams from around the world against each other. Our team from BITS Pilani participated in FSAE Italy '14, and was ranked 14th out of 46 teams in vehicle design. My contributions to the team were focussed on the design and fabrication of a double wishbone push-rod suspension system for the <a href="https://www.sae.org/attend/student-events/">Formula SAE</a> prototype. The work I did included the design and optimization of the bell-crank geometry, design and fabrication of the push-rod and a-arm geometry, and the design of the wheel hub. I also worked on calculating the roll center migration, spring rates, roll rates, anti-squat/anti-dive and the suspension frequency for the car.</p>
                            <a class="btn btn--strokeinv full-width" href="http://inspiredkarters-fs.com/" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->


                <!-- Sense -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-sense.jpg" class="thumb-link" title="Sense" data-size="2100x1400">
                                <img src="images/portfolio/sense.jpg" srcset="images/portfolio/sense.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Sense</h3>
                            <p class="item-folio__cat">
                                Android app serving all its sensor data via web
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <div class="item-folio__caption">
                            <p style="margin-bottom: 1rem">The Sense app was developed with the sole purpose of serving a developer with his needs. While working on robots, I often faced the issue where I had to buy multiple expensive sensors in order to make it perceptive of it's environment. This app alleviates this need by streaming all the sensor information(GPS, IMU, Camera, etc) from your android smartphone to a web-server. A supporting ROS Package is also developed to make it easy for developers to directly subscribe to useful topics and use them without the headache of installing device drivers, etc.</p>
                            <!-- <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/NASA-Astrobee" target="_blank" style="width: 30%; margin-left: 0;">Android App</a> -->
                        </div>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Simultaneous Localization & Mapping-->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-slam.jpg" class="thumb-link" title="SLAM Map" data-size="2100x1400">
                                <img src="images/portfolio/slam.jpg" srcset="images/portfolio/slam.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Simultaneous Localization & Mapping</h3>
                            <p class="item-folio__cat">
                                Particle Filter based SLAM on a differential drive robot
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <div class="item-folio__caption">
                            <p style="margin-bottom: 1rem">In this project, we develop a simple particle filter based SLAM algorithm on a hobby differential drive robot using a single channel Scanse Lidar. We implemented an occupancy gird based mapping mechanism, particle filter based localization algorithm and <a href="http://robotfrontier.com/">Yamauchi's autonomous exploration</a> algorithm on a differential mobile robot running on a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">raspberry pi3</a> and <a href="https://beagleboard.org/black">beaglebone black</a>. My contributions to the team included implementations of the action model, sensor model, the particle filter and the exploration algorithm. I also worked on the low-level control structure of the robot to minimize latency in the receiving and sending of commands.</p>
                            <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/SLAM/blob/master/BotLab%20Report.pdf" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                        </div>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->



                <!-- Pedestrian Tracking -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-ped.jpg" class="thumb-link" title="Pedestrian Tracking" data-size="2100x1400">
                                <img src="images/portfolio/ped.jpg" srcset="images/portfolio/ped.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Pedestrian Tracking</h3>
                            <p class="item-folio__cat">
                                Mask R-CNN based Pedestrian Tracking
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <div class="item-folio__caption">
                            <p style="margin-bottom: 1rem">Matterport's implementation of <a href="https://github.com/matterport/Mask_RCNN">Mask R-CNN</a> is used in this application and slightly modified to detect only pedestrians <em>(to keep computational requirements low)</em>. On top of this, we use <a href="http://www.diva-portal.org/smash/get/diva2:273847/FULLTEXT01.pdf">Gunner Farneback's algorithm</a> to compute the dense optical flow in each of the successive video frames. Since no ground truth is known here (as we do track pedestrians live using a mono camera), we use the instance segmentation given to us by Mask R-CNN and compute the net motion for each of the segments. We then use a particle filter for tracking one of the segments.</p>
                            <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/Mask-RCNN-Pedestrian-Detection" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                        </div>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Swarm Mapping -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-swarm.jpg" class="thumb-link" title="Swarm Robotics" data-size="2100x1400">
                                <img src="images/portfolio/swarm.jpg" srcset="images/portfolio/swarm.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Swarm Mapping and Control</h3>
                            <p class="item-folio__cat">
                                Aerial and Ground Robot Swarm
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">This project is an effort by <a href="https://tardec.army.mil/"> TARDEC</a> towards using swarm robotics for recconnaisance and surveillance. In this project, I worked on multi-robot mapping and resilient control where the swarm as a whole operates without any issue, even if some agents constituting the swarm are malicious. We used a swarm of heterogeneous robots: <a href="https://www.bitcraze.io/crazyflie-2/">CrazyFiles</a> and <a href="https://store.aionrobotics.com/products/r1-ardupilot">Aion R1 Rovers</a> to provide both aerial and ground functionality. <a href="http://www-personal.umich.edu/~dpanagou/">Dr. Dimitra Panagou</a> guided us through the project. Video demonstrations of the algorithm in action, and Gazebo Simulations will be uploaded soon.</p>
                            <!-- <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/crazyswarm" target="_blank" style="width: 30%; margin-left: 0;">Link</a> -->
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- GTA V -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-gta.jpg" class="thumb-link" title="3D Bounding Box Regression" data-size="2100x1400">
                                <img src="images/portfolio/gta.jpg" srcset="images/portfolio/gta.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">3D Bounding Box Regression</h3>
                            <p class="item-folio__cat">
                                3D Vehicle Detection and Bounding Box Regression
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">This project involves 2 parts: (i) Image Classification , (ii) Vehicle Detection and 3D Bounding Box regression. The GTA 10k dataset was used for this project and a total of 41 teams had participated in this private competition on Kaggle. A custom 20 layer SE-ResNet was implemented in PyTorch for classifying each of the images into one of the 23 pre-determined classes. Once classified, 3D bounding boxes were regressed using YOLO and geometry as outlined in <a href="https://arxiv.org/abs/1612.00496">this</a> work by A.Mousavian et al. We secured the 5th position in the 1st competition and 7th in the 2nd competition. Our classification accuracy was ~73% and the MSE for the centroid was ~9, whereas the same for the winning team was ~79% and ~4.3 respectively.</p>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->


                <!-- AR Control -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-arcontrol.jpg" class="thumb-link" title="Unsupervised Learning - Augmented Reality" data-size="2100x1400">
                                <img src="images/portfolio/arcontrol.jpg" srcset="images/portfolio/arcontrol.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Unsupervised Learning - Augmented Reality</h3>
                            <p class="item-folio__cat">
                                Unsupervised Learning based on GMM
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">This project presents an unsupervised learning algorithm by which an aerial robot can stream assistive camera views, which are unknown a priori, to a human whose attention is split between an arbitrary number of complex tasks. This is accomplished by tracking the human’s head motions during multitasking and then fitting this data to a visual interest function, modeled as a mixture of Gaussians, via online expectation maximization. This function informs a dynamic coverage controller which then directs the robot to patrol those regions most visually interesting to the human.</p>
                            <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/AR-unsupervised-learning" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                            <a class="btn btn--strokeinv full-width" href="https://vimeo.com/297490185" target="_blank" style="width: 30%; margin-left: 0;">Demo</a>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Kin Sim-->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-kinsim.jpg" class="thumb-link" title="Swarm Robotics" data-size="2100x1400">
                                <img src="images/portfolio/kinsim.jpg" srcset="images/portfolio/kinsim.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Robot Kinematics Simulator</h3>
                            <p class="item-folio__cat">
                                Javascript based Kinematic Simulator for Robotic Manipulators
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">The simulator was built as part of one of my <a href="https://autorob.github.io/">courses</a> here at Michigan. It is capable of interfacing with ROS over the web, giving anyone access to control a robot through any operating system. Given the URDF of a robot, the simulator is capable of automatically parsing the structure of the robot and calculating the forward <em>(using matrix stack)</em> and inverse kinematics <em>(using cyclic co-ordinate descent)</em>. Features such as object following and trajectory planning using RRT-Connect and other algorithms is built into the simulator.</p>
                            <a class="btn btn--strokeinv full-width" href="https://github.com/sahibdhanjal/Robot-Kinematic-Simulator" target="_blank" style="width: 30%; margin-left: 0;">Link</a>
                            <a class="btn btn--strokeinv full-width" href="projects/kinematic simulator/home.html" target="_blank" style="width: 30%; margin-left: 0;">Demo</a>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Pendulum-->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-pend.jpg" class="thumb-link" title="Swarm Robotics" data-size="2100x1400">
                                <img src="images/portfolio/pend.jpg" srcset="images/portfolio/pend.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Game Physics - Pendulum Simulations</h3>
                            <p class="item-folio__cat">
                                Javascript based Simulator for Single, Double and Cart Pole Pendulums
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">One of the most trivial control problems is that of a pendulum. In this project, a simple PID control structure was written for controlling the pendulum. Some of the prevalent integrators were implemented for the physics of the simulation : Euler Integrator, Verlet Integrator, Velocity Verlet Integrator and the Runge Kutta (RK4) integrator.</p>
                            <a class="btn btn--strokeinv full-width" href="projects/pendulum/pendularm1.html" target="_blank" style="width: 30%; margin-left: 0;" title="Single Pendulum Simulation">Demo-1</a>
                            <a class="btn btn--strokeinv full-width" href="projects/pendulum/pendularm2.html" target="_blank" style="width: 30%; margin-left: 0;" title="Double Pendulum Simulation">Demo-2</a>
                            <a class="btn btn--strokeinv full-width" href="projects/pendulum/cartpole.html" target="_blank" style="width: 30%; margin-left: 0;" title="Cart Pole Simulation">Demo-3</a>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Balance Bot -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-balance.jpg" class="thumb-link" title="Autonomous Balance Bot" data-size="2100x1400">
                                <img src="images/portfolio/balance.jpg" srcset="images/portfolio/balance.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Autonomous Balance Bot</h3>
                            <p class="item-folio__cat">
                                Self Balancing two-wheeled bot
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">This project involved us building an autonomous balancebot from scratch. Tasks involved the mechanical design of the bot, the hardware design of the circuit board and finally the code base running the robot. The robot used a cascaded PID controller to maintain it's balance while navigating through obstacle courses with the help of wheel odometry and motion capture providing positional feedback.</p>
                            <a class="btn btn--strokeinv full-width" href="https://vimeo.com/316239288" target="_blank" style="width: 30%; margin-left: 0;">Demo</a>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Auto Arm -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-aarm.jpg" class="thumb-link" title="Vision Based Autonomous Robotic Arm" data-size="2100x1400">
                                <img src="images/portfolio/aarm.jpg" srcset="images/portfolio/aarm.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Vision Based Autonomous Robotic Arm</h3>
                            <p class="item-folio__cat">
                                Autonomous Robotic Arm controlled via visual cues
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">The aim of this project was to automate redundant tasks using a robotic arm. The equipment we were provided with were a <a href="https://www.xbox.com/en-US/xbox-one/accessories/kinect">Microsoft Kinect</a> and a dynamixel arm with four degrees of freedom - RRR:R. Our task was to design an efficiemt gripping mechanism for the robot and detect different colored cubes using depth maps and images streamed from the overhead Kinect. Once done, we were to design a Spline -based trajectory algorithm for smooth motion of the arm and complete 5 assigned tasks whose details were predefined.</p>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- Gesture Arm -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-garm.jpg" class="thumb-link" title="Gesture Controlled Robotic Arm" data-size="2100x1400">
                                <img src="images/portfolio/garm.jpg" srcset="images/portfolio/garm.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Gesture Controlled Robotic Arm</h3>
                            <p class="item-folio__cat">
                                Gesture Controlled Robotic Arm with Arduino and XBee
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">A gesture controlled robotic arm was designed and fabricated under the guidance of <a href="https://scholar.google.co.in/citations?user=rwWOPY8AAAAJ&hl=en">Dr. R.K.Mittal</a>. Arduino-UNOs (one on the hand and the other controlling the robot) as our micro-controllers, 2 Inertial Measurement Units- MPU 6050 (to sense hand gestures and provide feedback) and the XBee for wireless communication. An application in Processing was also developed so that the arm could be manually controlled via sliders, instead of the IMU, when desired. The arm was capable of augmenting human capabilities with a reachable spherical workspace of radius 2m and payload capacity of 500gm.</p>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

                <!-- White Board -->
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">

                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-warm.jpg" class="thumb-link" title="Portable White Board Cleaner" data-size="2100x1400">
                                <img src="images/portfolio/warm.jpg" srcset="images/portfolio/warm.jpg" alt="">
                            </a>
                        </div>

                        <div class="item-folio__text">
                            <h3 class="item-folio__title">Portable White Board Cleaner</h3>
                            <p class="item-folio__cat">
                                Portable White Board Cleaner Concept with Arduino
                            </p>
                        </div>

                        <a href="#" class="item-folio__project-link" title="View Brief" target="_blank">
                            View Brief
                        </a>

                        <span class="item-folio__caption">
                            <p style="margin-bottom: 1rem">This project focussed on the conceptualization, design and fabrication of a state-of-the-art whiteboard cleaner which, unlike conventional ones, was portable and inexpensive. The design was based on a simple RR:PR manipulator structure and was capable of cleaning boards of sizes upto 4' x 6' autonomously on the click of a button. The prototype was powered by an Arduino UNO and 4 servo motors. The results of this research was presented in the <a href="https://upcon15.iiita.ac.in/">IEEE UPCON'15</a> conference at IIIT, Allahabad.</p>
                        </span>

                    </div>
                    <!-- end item-folio -->
                </div>
                <!-- end masonry__brick -->

            </div>
            <!-- end masonry -->
        </div>
        <!-- end masonry-wrap -->
    </section>
    <!-- end s-works -->


    <!-- contact
    ================================================== -->
    <section id="contact" class="s-contact">
        <div class="col-full cl-copyright" style="margin-bottom: 1rem; margin-top: 1rem;">
            <script>document.write(new Date().getFullYear());</script> | <a href="https://sahibdhanjal.github.io/">Sahib Dhanjal</a>
            <ul class="contact-social">
                <li><a href="https://www.linkedin.com/in/sahibdhanjal/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
                <li><a href="https://github.com/sahibdhanjal/" target="_blank"><i class="fa fa-github"></i></a></li>
                <li><a href="https://www.behance.net/sahibdhanjal" target="_blank"><i class="fa fa-behance"></i></a></li>
                <li><a href="https://twitter.com/sahib_dhanjal" target="_blank"><i class="fa fa-twitter"></i></a></li>
                <li><a href="https://www.instagram.com/sahibdhanjal/" target="_blank"><i class="fa fa-instagram"></i></a></li>
            </ul>
        </div>
    </section>
    <!-- end s-contact -->


    <!-- photoswipe background
    ================================================== -->
    <div aria-hidden="true" class="pswp" role="dialog" tabindex="-1">

        <div class="pswp__bg"></div>
        <div class="pswp__scroll-wrap">

            <div class="pswp__container">
                <div class="pswp__item"></div>
                <div class="pswp__item"></div>
                <div class="pswp__item"></div>
            </div>

            <div class="pswp__ui pswp__ui--hidden">
                <div class="pswp__top-bar">
                    <div class="pswp__counter"></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button><button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button> <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                    <div class="pswp__preloader">
                        <div class="pswp__preloader__icn">
                            <div class="pswp__preloader__cut">
                                <div class="pswp__preloader__donut"></div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                    <div class="pswp__share-tooltip"></div>
                </div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button> <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>
                <div class="pswp__caption">
                    <div class="pswp__caption__center"></div>
                </div>
            </div>

        </div>
    </div>
    <!-- end photoSwipe background -->

    <!-- Java Script
    ================================================== -->
    <script src="js/jquery-3.2.1.min.js"></script>
    <script src="js/plugins.js"></script>
    <script src="js/main.js"></script>

</body>

</html>
