<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
    <!-- Full story -->
    <script> window['_fs_debug'] = false; window['_fs_host'] = 'fullstory.com'; window['_fs_org'] = 'NSFNC'; window['_fs_namespace'] = 'FS'; (function(m,n,e,t,l,o,g,y){ if (e in m) {if(m.console && m.console.log) { m.console.log('FullStory namespace conflict. Please set window["_fs_namespace"].');} return;} g=m[e]=function(a,b,s){g.q?g.q.push([a,b,s]):g._api(a,b,s);};g.q=[]; o=n.createElement(t);o.async=1;o.crossOrigin='anonymous';o.src='https://'+_fs_host+'/s/fs.js'; y=n.getElementsByTagName(t)[0];y.parentNode.insertBefore(o,y); g.identify=function(i,v,s){g(l,{uid:i},s);if(v)g(l,v,s)};g.setUserVars=function(v,s){g(l,v,s)};g.event=function(i,v,s){g('event',{n:i,p:v},s)}; g.shutdown=function(){g("rec",!1)};g.restart=function(){g("rec",!0)}; g.log = function(a,b) { g("log", [a,b]) }; g.consent=function(a){g("consent",!arguments.length||a)}; g.identifyAccount=function(i,v){o='account';v=v||{};v.acctId=i;g(o,v)}; g.clearUserCookie=function(){}; })(window,document,window['_fs_namespace'],'script','user');
    </script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-113408615-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-113408615-1');
    </script>

    <!--- basic page needs
    ================================================== -->
    <meta charset="utf-8">
    <title>Sahib Dhanjal | Roboticist</title>
    <meta name="author" content="Sahib Singh Dhanjal">
    <!-- <meta http-equiv="refresh" content="120"> -->
    <meta name= "description" content= " Sahib Singh Dhanjal Portfolio website">
    <meta name="keywords" content="portfolio, star wars, star, wars, robot, robotics, roboticist, University, of, michigan, university of michigan, ann arbor, flint, dearborn, bits, pilani, birla institute of technology and science, birla, institute, technology, science, pilani, hyderabad, goa, personal, projects, robot Kinematic, kinematics, path planner, path, planning, turtlebot, masters, football, soccer, Programmer, coder, coding, programming, machine learning, deep learning, tensor flow, computer vision, C/C++, JavaScript, java, python,Formula, student, fsae, italy, robotx, maritime, autonmous, slam, localization, mapping, vehicle, dynamics, inspired, Karters, fs">

    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <link rel="stylesheet" href="css/base.css">
    <link rel="stylesheet" href="css/vendor.css">
    <link rel="stylesheet" href="css/main.css">

    <style type="text/css" media="screen">
        .s-styles {
            background: white;
            padding-top: 15rem;
            padding-bottom: 12rem;
        }
    </style>

    <!-- script
    ================================================== -->
    <script src="js/modernizr.js"></script>
    <script src="js/pace.min.js"></script>

    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <link rel="icon" href="images/favicon.ico" type="image/x-icon">

</head>

<body id="top">

    <!-- home
    ================================================== -->
    <section id="home" style="height: 140px; width: 100%; margin:0 auto;">
        <a id="hoverer" href="index.html"><h1 class="display-1" style="color: white; text-align: center;margin-top: 5rem; margin-bottom: 2rem">Sahib Dhanjal</h1></a>
        <!-- <a class="btn btn--strokeinv full-width smoothscroll" href="#tech" style="width: 32%">Technical Projects</a> -->
        <!-- <a class="btn btn--strokeinv full-width smoothscroll" href="#stats" style="width: 32%">Design Projects</a> -->
        <!-- <a class="btn btn--strokeinv full-width smoothscroll" href="#0" style="width: 32%">Extra-Curriculum</a> -->
    </section> <!-- end s-home -->


    <!-- tech projects
    ================================================== -->
    <section id="tech" class="s-styles" style="padding-top: 5rem">
<!--
        <div class="row narrow section-intro add-bottom text-center">

            <div class="col-twelve tab-full">
                <h1 class="display-1">Technical Projects</h1>
            </div>

        </div>
 -->


       <!-- Radio Inertial -->

       <div class="row">

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-wifi.jpg"
                    srcset="images/portfolio/gallery/g-wifi.jpg 1000w,
                    images/portfolio/gallery/g-wifi.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

            <div class="col-six tab-full">

                <h3 class="subhead">Visual-Radio-Inertial Positioning System</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.42">This project involves the development of a state-of-the-art localization system for truly mobile devices, such as smartphones. The main aim of the project is to provide with a means of localization in indoor/GPS-denied environments. A deep neural network capable of differentiating between LOS/NLOS measurements has been architected. Simulations in MATLAB and Python have been developed for the 2D and 3D case. Experiments with the <a href="https://fetchrobotics.com/robotics-platforms/fetch-mobile-manipulator/">Fetch</a> robot were performed with an RMSE of around 2m. The project was done under the guidance of <a href="https://www.maanighaffari.com/">Dr. Maani Ghaffari</a>.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>ROS, Fetch Robot, Fast SLAM v1, Particle Filter, Deep Learning, VIO</small></p>
                <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/DeepLocNet" target="_blank">Project Link</a>

            </div>

        </div> <!-- end row -->

        <!-- GTA V -->
       <div class="row">

            <div class="col-six tab-full">

                <h3 class="subhead">3D Bounding Box Regression</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.32">This project involves 2 parts: (i) Image Classification , (ii) Vehicle Detection and 3D Bounding Box regression. The GTA 10k dataset was used for this project and a total of 41 teams had participated in this private competition on Kaggle. A custom 20 layer SE-ResNet was implemented in PyTorch for classifying each of the images into one of the 23 pre-determined classes. Once classified, 3D bounding boxes were regressed using YOLO and geometry as outlined in <a href="https://arxiv.org/abs/1612.00496">this</a> work by A.Mousavian et al. We secured the 5th position in the 1st competition and 7th in the 2nd competition. Our classification accuracy was ~73% and the MSE for the centroid was ~9, whereas the same for the winning team was ~79% and ~4.3 respectively.
                </p>
                <p><small><strong>keywords: </strong>YOLO, SE ResNet, Deep Learning, GTA 10k Dataset</small></p>

            </div>

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-gta.jpg"
                    srcset="images/portfolio/gallery/g-gta.jpg 1000w,
                    images/portfolio/gallery/g-gta.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>


        </div> <!-- end row -->

        <hr>

       <!-- Swarm Robotics -->

       <div class="row">

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-swarm.jpg"
                    srcset="images/portfolio/gallery/g-swarm.jpg 1000w,
                    images/portfolio/gallery/g-swarm.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

            <div class="col-six tab-full">

                <h3 class="subhead">Autonomous Swarm Mapping & Control</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.42">This project is an effort by TARDEC towards using swarm robotics for recconnaisance and surveillance. In this project, I worked on multi-robot mapping and resilient control where the swarm as a whole operates without any issue, even if some agents constituting the swarm are malicious. We used a swarm of heterogeneous robots: <a href="https://www.bitcraze.io/crazyflie-2/">CrazyFiles</a> and <a href="https://store.aionrobotics.com/products/r1-ardupilot">Aion R1 Rovers</a> to provide both aerial and ground functionality. <a href="http://www-personal.umich.edu/~dpanagou/">Dr. Dimitra Panagou</a> guided us through the project. Video demonstrations of the algorithm in action, and Gazebo Simulations will be uploaded soon.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>swarm robotics, resilient control, ROS, Gazebo, quadrotors, ground robots, SLAM, motion capture</small></p>

                <!-- <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/crazyswarm" target="_blank">Project Link</a> -->

            </div>

        </div> <!-- end row -->

        <hr>

        <!-- AR Control -->

       <div class="row">

            <div class="col-six tab-full">

                <h3 class="subhead">Unsupervised Learning - Augmented Reality</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.32">This project presents an unsupervised learning algorithm by which an aerial robot can stream assistive camera views, which are unknown a priori, to a human whose attention is split between an arbitrary number of complex tasks. This is accomplished by tracking the humanâ€™s head motions during multitasking and then fitting this data to a visual interest function, modeled as a mixture of Gaussians, via online expectation maximization. This function informs a dynamic coverage controller which then directs the robot to patrol those regions most visually interesting to the human.
                </p>
                <p><small><strong>keywords: </strong>ROS, AR, quadrotors, expectation maximisation, GMM</small></p>

                <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/AR-unsupervised-learning" target="_blank">Project Link</a>

            </div>

            <div class="col-six tab-full">
                <div class="video-container">
                <iframe src="https://player.vimeo.com/video/297490185" width="560" height="380" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                </div>
            </div>


        </div> <!-- end row -->

        <hr>


        <!-- ASTRONET -->
        <div class="row">

            <div class="col-six tab-full">
                <div class="video-container">
                <iframe src="https://player.vimeo.com/video/282063033" width="560" height="380" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                </div>
            </div>


            <div class="col-six tab-full">

                <h3 class="subhead">NASA Astronet</h3>


                <p class="drop-cap" style="text-align: justify; line-height: 1.32">The <a href="https://www.nasa.gov/directorates/spacetech/strg/ecf2016/AstroNet.html">AstroNet</a> Simulator is developed as an extension to NASA's <a href="https://www.nasa.gov/astrobee">open-source simulator</a>. Coverage and navigation algorithms for each of the Astrobee Robots are developed in an immersive VR-based ISS environment. <a href="http://wiki.ros.org/kinetic">ROS Kinetic</a> is used for simulating the algorithms, and to interface with the quadcopters (representing astrobee robots in our environment). <!-- An immersive VR-based environment of the whole International Space Station, with the robots in it, has been implemented and can be visualized on the <a href="https://www.oculus.com/rift/#oui-csl-rift-games=robo-recall">Oculus Rift</a>. --></p>

                <p><small><strong>keywords: </strong>ROS, Gazebo, multi-agent control, quadrotors, autonomous exploration, Oculus Rift</small></p>

                <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/NASA-Astrobee" target="_blank">Project Link</a>
            </div>

        </div> <!-- end row -->

        <hr>

        <!-- ROBOTX -->
       <div class="row">

            <div class="col-six tab-full">

                <h3 class="subhead">AUVSI Robot-X</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.32">AUVSI's <a href="http://robotx.org/">Robot-X</a> competition is an attempt at automating surface vessels to revolutionize the marine industry. The robot should be capable of performing several tasks such as SLAM, Trajectory Planning, Obstacle Avoidance, etc. My contributions to the project are in SLAM(Velodyne HDL32, Ladybug 3 and GPS/IMU module used as sensors), Trajectory Planning, 3D Object Detection, and Network and Communication Setup. The whole framework is being developed on ROS Kinetic.
                </p>
                <p><small><strong>keywords: </strong>ROS, autonomous vehicle, sensor calibration, SLAM, cascaded PID, sensor fusion, lidar, YOLO</small></p>

                <a class="btn btn--stroke full-width" href="https://github.com/MichiganRobotX" target="_blank">Project Link</a>

            </div>

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-wamv.jpg"
                    srcset="images/portfolio/gallery/g-wamv.jpg 1000w,
                    images/portfolio/gallery/g-wamv.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>


        </div> <!-- end row -->

        <hr>

       <!-- TURTLEBOT -->

       <div class="row">

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-turt.jpg"
                    srcset="images/portfolio/gallery/g-turt.jpg 1000w,
                    images/portfolio/gallery/g-turt.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

            <div class="col-six tab-full">

                <h3 class="subhead">Path Planning & Multi-Agent Exploration</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.42">This project involves comparative analysis of state-of-the-art path planning and multi-agent exploration algorithms via simulation and experimentation. Simmulations are performed on 50+ fabricated grid maps of size 50 x 50 on a python based simulator. To validate the results, experiments with <a href="https://www.turtlebot.com/turtlebot2/">Turtlebots</a> are also performed. Nodes for the studied path planning and exploration algorithms are written and 10 different laboratory environments are explored.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>ROS, Turtlebot 2, <em>Path Finding</em> - JPS/A*/Dijkstra/BFS, <em>Exploration</em> - CAC/Yamauchi/Burgard/Faigl, multi-agent exploration, path planning</small></p>

                <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/Path-Planning-Simulator" style="width: 49%"target="_blank">Project Link</a>
                <a class="btn btn--stroke full-width" href="websites/path planning simulator/index.html" style="width: 49%">Demo</a>


            </div>

        </div> <!-- end row -->

        <hr>

        <!-- posenet++ -->

       <div class="row">

            <div class="col-six tab-full">

                <h3 class="subhead">PoseNet++</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.22">An online-deep learning based-data labeling paradigm derived from structural motion is implemented. We directly label (6-DOF measurements) the input data (camera video feed) streamed from a mobile camera using this paradigm. This labeled data is then used to train <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf">PoseNet</a>, which acts as the sensor model for <a href="http://people.csail.mit.edu/kaess/isam/">Incremental Smoothing and Mapping (iSAM)</a>. GPS data from the used dataset's is used to build the action model. Georgia Tech's <a href="https://borg.cc.gatech.edu/">GTSAM</a> is then used for simulation. The algorithm is also implemented on a differential drive mobile robot.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>deep learning, PoseNet, kidnapped robot, iSAM, GTSAM, NCLT</small></p>

                <a class="btn btn--stroke full-width" href="https://posenet-mobile-robot.github.io/"target="_blank">Project Link</a>
            </div>
            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-posenet.jpg"
                    srcset="images/portfolio/gallery/g-posenet.jpg 1000w,
                    images/portfolio/gallery/g-posenet.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>


        </div> <!-- end row -->


        <hr>
       <!-- fsae -->

       <div class="row">

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-fs.jpg"
                    srcset="images/portfolio/gallery/g-fs.jpg 1000w,
                    images/portfolio/gallery/g-fs.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

            <div class="col-six tab-full">

                <h3 class="subhead">Formula SAE - Italy'14</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.32">My contributions to the team were focussed on the design and fabrication of a double wishbone push-rod suspension system for the <a href="https://www.sae.org/attend/student-events/">Formula SAE</a> prototype. The work I did included the design and optimization of the bell-crank geometry, design and fabrication of the push-rod and a-arm geometry, and the design of the wheel hub. I also worked on calculating the roll center migration, spring rates, roll rates, anti-squat/anti-dive and the suspension frequency for the car.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>Formula SAE, suspension design, roll center migration, double wishbone suspension, fabrication, Solidworks, ANSYS, MSC Adams</small></p>

                <a class="btn btn--stroke full-width" href="http://inspiredkarters-fs.com/"target="_blank">Project Link</a>
            </div>

        </div> <!-- end row -->

        <hr>
        <!-- kinsim -->

       <div class="row">

            <div class="col-six tab-full">

                <h3 class="subhead">Robot Kinematics Simulator</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.22">The simulator was built as part of one of my <a href="https://autorob.github.io/">courses</a> here at Michigan. It is capable of interfacing with ROS over the web, giving anyone access to control a robot through any operating system. Given the URDF of a robot, the simulator is capable of automatically parsing the structure of the robot and calculating the forward <em>(using matrix stack)</em> and inverse kinematics <em>(using cyclic co-ordinate descent)</em>. Features such as object following and trajectory planning using RRT-Connect and other algorithms is built into the simulator.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>RRT/RRT*/RRT-Connect, CCD, forward/inverse kinematics, matrix stack, URDF parsing, robot webtools</small></p>

                <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/Robot-Kinematic-Simulator" style="width: 49%"target="_blank">Project Link</a>
                <a class="btn btn--stroke full-width" href="websites/kinematic simulator/home.html" style="width: 49%">Demo</a>

            </div>
            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-kinsim.jpg"
                    srcset="images/portfolio/gallery/g-kinsim.jpg 1000w,
                    images/portfolio/gallery/g-kinsim.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>


        </div> <!-- end row -->


        <hr>
       <!-- slam -->

       <div class="row">

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-slam.jpg"
                    srcset="images/portfolio/gallery/g-slam.jpg 1000w,
                    images/portfolio/gallery/g-slam.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

            <div class="col-six tab-full">

                <h3 class="subhead">Simultaneous Localization and Mapping</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.22">We implemented an occupancy gird based mapping mechanism, particle filter based localization algorithm and <a href="http://robotfrontier.com/">Yamauchi's autonomous exploration</a> algorithm on a differential mobile robot running on a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">raspberry pi3</a> and <a href="https://beagleboard.org/black">beaglebone black</a>. My contributions to the team included implementations of the action model, sensor model, the particle filter and the exploration algorithm. I also worked on the low-level control structure of the robot to minimize latency in the receiving and sending of commands.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>localization, mapping, lidar, LCM, particle filter, raspberry pi 3, beaglebone black, Yamauchi's exploration</small></p>

                <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/SLAM/blob/master/BotLab%20Report.pdf" target="_blank">Project Link</a>

            </div>

        </div> <!-- end row -->

        <hr>

        <!-- pedtrack -->

       <div class="row">

            <div class="col-six tab-full">

                <h3 class="subhead">Mask R-CNN based Pedestrian Tracking</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.22">Matterport's implementation of <a href="https://github.com/matterport/Mask_RCNN">Mask R-CNN</a> is used in this application and slightly modified to detect only pedestrians <em>(to keep computational requirements low)</em>. On top of this, we use <a href="http://www.diva-portal.org/smash/get/diva2:273847/FULLTEXT01.pdf">Gunner Farneback's algorithm</a> to compute the dense optical flow in each of the successive video frames. Since no ground truth is known here (as we do track pedestrians live using a mono camera), we use the instance segmentation given to us by Mask R-CNN and compute the net motion for each of the segments. We then use a particle filter for tracking one of the segments.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong>deep learning, convnets, particle filter, dense optical flow, pedestrian tracking</small></p>

                <a class="btn btn--stroke full-width" href="https://github.com/sahibdhanjal/Mask-RCNN-Pedestrian-Detection" target="_blank">Project Link</a>

            </div>
            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-ped.jpg"
                    srcset="images/portfolio/gallery/g-ped.jpg 1000w,
                    images/portfolio/gallery/g-ped.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>


        </div> <!-- end row -->

        <hr>



       <!-- pendulum -->

       <div class="row">

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-pend.jpg"
                    srcset="images/portfolio/gallery/g-pend.jpg 1000w,
                    images/portfolio/gallery/g-pend.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

            <div class="col-six tab-full">

                <h3 class="subhead">Game Physics - Pendulum Simulations</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.32">One of the most trivial control problems is that of a pendulum. In this project, a simple PID control structure was written for controlling the pendulum. Some of the prevalent integrators were implemented for the physics of the simulation : Euler Integrator, Verlet Integrator, Velocity Verlet Integrator and the Runge Kutta (RK4) integrator.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong><em>integrators</em> - RK4, velocity verlet, verlet, euler, pendulum, cart pole </small></p>

                <a class="btn btn--stroke full-width" href="websites/pendulum/pendularm1.html" style="width: 49%">Single Pendulum</a>
                <a class="btn btn--stroke full-width" href="websites/pendulum/pendularm2.html" style="width: 49%">Double Pendulum</a>
                <a class="btn btn--stroke full-width" href="websites/pendulum/cartpole.html" >Cart Pole Simulation</a>


            </div>

        </div> <!-- end row -->

        <hr>

       <!-- Balance Bot -->

       <div class="row">


            <div class="col-six tab-full">

                <h3 class="subhead">Autonomous Balance Bot</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.32">This project involved us building an autonomous balancebot from scratch. Tasks involved the mechanical design of the bot, the hardware design of the circuit board and finally the code base running the robot. The robot used a cascaded PID controller to maintain it's balance while navigating through obstacle courses with the help of wheel odometry and motion capture providing positional feedback.
                </p>
                <p><small><strong>keywords: </strong>PID, cascaded control, balancebot</small></p>

            </div>

            <div class="col-six tab-full">
                <div class="video-container">
                <iframe src="https://player.vimeo.com/video/316239288" width="640" height="460" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                </div>
            </div>

        </div> <!-- end row -->

        <hr>
        <!-- autoarm -->

       <div class="row">
            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-aarm.jpg"
                    srcset="images/portfolio/gallery/g-aarm.jpg 1000w,
                    images/portfolio/gallery/g-aarm.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

            <div class="col-six tab-full">

                <h3 class="subhead">Vision Based Autonomous Robotic Arm</h3>


                <p class="drop-cap" style="text-align: justify; line-height: 1.62">The aim of this project was to automate redundant tasks using a robotic arm. The equipment we were provided with were a <a href="https://www.xbox.com/en-US/xbox-one/accessories/kinect">Microsoft Kinect</a> and a dynamixel arm with four degrees of freedom - RRR:R. Our task was to design an efficiemt gripping mechanism for the robot and detect different colored cubes using depth maps and images streamed from the overhead Kinect. Once done, we were to design a Spline -based trajectory algorithm for smooth motion of the arm and complete 5 assigned tasks whose details were predefined.
                </p>
                <p style="line-height: 1"><small><strong>keywords: </strong> - robotic arm, object detection, Kinect, forward/inverse kinematics, LCM, manipulator control, spline generation, gripper design</small></p>

            </div>


        </div> <!-- end row -->


        <hr>

       <!-- Whiteboard -->

       <div class="row">

            <div class="col-six tab-full">

                <h3 class="subhead">Portable White Board Cleaner</h3>

                <p class="drop-cap" style="text-align: justify; line-height: 1.42">This project focussed on the conceptualization, design and fabrication of a state-of-the-art whiteboard cleaner which, unlike conventional ones, was portable and inexpensive. The design was based on a simple RR:PR manipulator structure and was capable of cleaning boards of sizes upto 4' x 6' autonomously on the click of a button. The prototype was powered by an Arduino UNO and 4 servo motors. The results of this research was presented in the <a href="https://upcon15.iiita.ac.in/">IEEE UPCON'15</a> conference at IIIT, Allahabad.
                </p>

                <p style="line-height: 1"><small><strong>keywords: </strong> - robotic arm, whiteboard cleaner, forward/inverse kinematics, arduino, arm design</small></p>

                <a class="btn btn--stroke full-width" href="https://ieeexplore.ieee.org/document/7456702/" >Paper Link</a>

            </div>

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-warm.jpg"
                    srcset="images/portfolio/gallery/g-warm.jpg 1000w,
                    images/portfolio/gallery/g-warm.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>

        </div> <!-- end row -->


        <hr>

        <!-- gesture control -->

       <div class="row">

            <div class="col-six tab-full">

                <p><img src="images/portfolio/gallery/g-garm.jpg"
                    srcset="images/portfolio/gallery/g-garm.jpg 1000w,
                    images/portfolio/gallery/g-garm.jpg 500w"
                    sizes="(max-width: 500px) 100vw, 500px" alt=""></p>

            </div>
            <div class="col-six tab-full">

               <h3 class="subhead">Gesture Controlled Robotic Arm</h3>

               <p class="drop-cap" style="text-align: justify; line-height: 1.52">A gesture controlled robotic arm was designed and fabricated under the guidance of <a href="https://scholar.google.co.in/citations?user=rwWOPY8AAAAJ&hl=en">Dr. R.K.Mittal</a>. Arduino-UNOs (one on the hand and the other controlling the robot) as our micro-controllers, 2 Inertial Measurement Units- MPU 6050 (to sense hand gestures and provide feedback) and the XBee for wireless communication. An application in Processing was also developed so that the arm could be manually controlled via sliders, instead of the IMU, when desired. The arm was capable of augmenting human capabilities with a reachable spherical workspace of radius 2m and payload capacity of 500gm.
                </p>

                <p style="line-height: 1"><small><strong>keywords: </strong> - robotic arm, gesture control, forward/inverse kinematics, arduino, arm design</small></p>

            </div>


        </div> <!-- end row -->

    </section>



    <!-- design projects
    ================================================== -->
<!--     <section id="stats" class="s-stats">


        <div class="row section-header" data-aos="fade-up">
            <div class="col-full">
                <h3 class="subhead">Photography & Design</h3>
            </div>
        </div>

        <div class="row masonry-wrap">
            <div class="masonry">
                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-nasa.jpg" class="thumb-link" title="NASA Astronet" data-size="950x635">
                                <img src="images/portfolio/nasa.jpg"
                                     srcset="images/portfolio/nasa.jpg 1x, images/portfolio/nasa@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-wamv.jpg" class="thumb-link" title="RobotX WAM-V" data-size="950x635">
                                <img src="images/portfolio/wamv.jpg"
                                     srcset="images/portfolio/wamv.jpg 1x, images/portfolio/wamv@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-turt.jpg" class="thumb-link" title="TurtleBot 2" data-size="950x635">
                                <img src="images/portfolio/turt.jpg"
                                     srcset="images/portfolio/turt.jpg 1x, images/portfolio/turt@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-posenet.jpg" class="thumb-link" title="Cambridge Dataset" data-size="950x635">
                                <img src="images/portfolio/posenet.jpg"
                                     srcset="images/portfolio/posenet.jpg 1x, images/portfolio/posenet@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-fs.jpg" class="thumb-link" title="Formula SAE" data-size="950x635">
                                <img src="images/portfolio/fs.jpg"
                                     srcset="images/portfolio/fs.jpg 1x, images/portfolio/fs@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-kinsim.jpg" class="thumb-link" title="Kinematics Simulator" data-size="950x635">
                                <img src="images/portfolio/kinsim.jpg"
                                     srcset="images/portfolio/kinsim.jpg 1x, images/portfolio/kinsim@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-slam.jpg" class="thumb-link" title="SLAM Map" data-size="950x635">
                                <img src="images/portfolio/slam.jpg"
                                     srcset="images/portfolio/slam.jpg 1x, images/portfolio/slam@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-ped.jpg" class="thumb-link" title="Pedestrian Tracking" data-size="950x635">
                                <img src="images/portfolio/ped.jpg"
                                     srcset="images/portfolio/ped.jpg 1x, images/portfolio/ped@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

                <div class="masonry__brick" data-aos="fade-up">
                    <div class="item-folio">
                        <div class="item-folio__thumb">
                            <a href="images/portfolio/gallery/g-pend.jpg" class="thumb-link" title="Double Pendulum" data-size="950x635">
                                <img src="images/portfolio/pend.jpg"
                                     srcset="images/portfolio/pend.jpg 1x, images/portfolio/pend@2x.jpg 2x" alt="">
                            </a>
                        </div>
                    </div>
                </div>

            </div>
        </div>
    </section>
 -->

    <!-- contact
    ================================================== -->
    <section id="contact" class="s-contact">

        <div class="row section-header">
            <div class="col-full">
                <h1 class="display-1 display-1--light">Get in touch</h1>
            </div>
        </div> <!-- end section-header -->

        <div class="row">
            <div class="col-full contact-main">
                <p>
                <a href="mailto:dhanjalsahib@gmail.com" class="contact-email">dhanjalsahib@gmail.com</a>
                <span class="contact-number">+1 (734) 239 2285</span>
                </p>
            </div> <!-- end contact-main -->
        </div> <!-- end row -->


         <div class="row">

            <div class="col-five tab-full contact-secondary">
                <h3 class="subhead subhead--light">Come Visit Me</h3>
                <p class="contact-address">
                    1103 Maiden Lane Court<br>
                    Ann Arbor, MI<br>
                    48105 US
                </p>
            </div> <!-- end contact-secondary -->

            <div class="col-five tab-full contact-secondary">
                <h3 class="subhead subhead--light">Follow Me</h3>
                <ul class="contact-social">
                    <!-- <li>
                        <a href="https://www.facebook.com/Sahib.Dhanjal.007" target="_blank"><i class="fab fa-facebook"></i></a>
                    </li> -->
                    <li>
                        <a href="https://twitter.com/sahib_dhanjal" target="_blank"><i class="fab fa-twitter"></i></a>
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/sahibdhanjal/" target="_blank"><i class="fab fa-linkedin"></i></a>
                    </li>
                    <li>
                        <a href="https://www.behance.net/sahibdhanjal" target="_blank"><i class="fab fa-behance"></i></a>
                    </li>
                    <li>
                        <a href="https://github.com/sahibdhanjal/" target="_blank"><i class="fab fa-github"></i></a>
                    </li>
                </ul> <!-- end contact-social -->

            </div> <!-- end contact-secondary -->

        </div> <!-- end row -->

        <div class="row">
            <div class="col-full cl-copyright">
                <span><!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="fa fa-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a> and modified by <a href="https://www.linkedin.com/in/sahibdhanjal/" target="_blank">Sahib Dhanjal</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></span>
            </div>
        </div>

        <div class="cl-go-top">
            <a class="smoothscroll" title="Back to Top" href="#top"><i class="icon-arrow-up" aria-hidden="true"></i></a>
        </div>

    </section> <!-- end s-contact -->


    <!-- photoswipe background
    ================================================== -->
    <div aria-hidden="true" class="pswp" role="dialog" tabindex="-1">

        <div class="pswp__bg"></div>
        <div class="pswp__scroll-wrap">

            <div class="pswp__container">
                <div class="pswp__item"></div>
                <div class="pswp__item"></div>
                <div class="pswp__item"></div>
            </div>

            <div class="pswp__ui pswp__ui--hidden">
                <div class="pswp__top-bar">
                    <div class="pswp__counter"></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button><button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button> <button class="pswp__button pswp__button--zoom" title=
                    "Zoom in/out"></button>
                    <div class="pswp__preloader">
                        <div class="pswp__preloader__icn">
                            <div class="pswp__preloader__cut">
                                <div class="pswp__preloader__donut"></div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                    <div class="pswp__share-tooltip"></div>
                </div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button> <button class="pswp__button pswp__button--arrow--right" title=
                "Next (arrow right)"></button>
                <div class="pswp__caption">
                    <div class="pswp__caption__center"></div>
                </div>
            </div>

        </div>

    </div> <!-- end photoSwipe background -->


    <!-- preloader
    ================================================== -->
    <div id="preloader">
        <div id="loader">
        </div>
    </div>


    <!-- Java Script
    ================================================== -->
    <script src="js/jquery-3.2.1.min.js"></script>
    <script src="js/plugins.js"></script>
    <script src="js/main.js"></script>
    <script src='https://cdn.rawgit.com/Verlangieri/robot-animation/master/app/vendor/three.min.js'></script>
    <script src='https://cdn.rawgit.com/Verlangieri/robot-animation/master/app/vendor/gsap.min.js'></script>
    <script src='https://cdn.rawgit.com/Verlangieri/robot-animation/master/app/vendor/dat.gui.min.js'></script>
    <script src='https://cdn.rawgit.com/Verlangieri/robot-animation/master/app/vendor/colladaLoader2.min.js'></script>
    <script  src="js/robot.js"></script>
</body>

</html>
